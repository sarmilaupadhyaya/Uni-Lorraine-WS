{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A very short introduction before to take the plunge\n",
    "\n",
    "<p>The objective fo the course is to understand what is \"Sentiment Analysis and Opinion Mining\" (SAOM).</p>\n",
    "\n",
    "<p>For that, I propose this first session consisting in discovering data used for this NLP task and a first model with all classical steps: data (tokenization, segmentation into train/dev/test parts), programmation of the model, evaluation of the performance.</p>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the positive/negative labels for movie reviews\n",
    "\n",
    "The objective of this programming work is to program a method for predicting the positive/negative label of a movie review.\n",
    "\n",
    "\"Positive\" or \"Negative\" is a binary opinion about something, here, a movie. The review explains what is good and what is not goodin the movie, and then, sommeone (the labeller) labels the review with \"+\" or \"-\" according to a labelling guideline.\n",
    "\n",
    "Thrn, if we have numerous reviews with \"+/-\" labels, it is possible to extract a predictive model which can give the \"+' pr the '-\" opinion to a new review.\n",
    "\n",
    "You will use a movie review database built by Pang and Lee, in 2008. This data provides textual data for movie reviews. I give below two examples of such movie reviews :\n",
    "\n",
    "The former : \"this film is extraordinarily horrendous and I'm not going to waste any more words on it.\" is quite negative.\n",
    "\n",
    "The latter : \"this three hour movie opens up with a view of singer/guitar player/musician/composer frank zappa rehearsing with his fellow band members. All the rest displays a compilation of footage, mostly from the concert at the palladium in new york city, halloween 1979. Other footage shows backstage foolishness, and amazing clay animation by Bruce Bickford. the performance of \"titties and beer\" played in this movie is very entertaining, with drummer terry bozzio supplying the voice of the devil. Frank's guitar solos outdo any van halen or hendrix I've ever heard. Bruce Bickford's outlandish clay animation is that beyond belief with zooms, morphings, etc. and actually, it doesn't even look like clay, it looks like meat.\" gives an positive opinion on the movie.\n",
    "\n",
    "<p>Pang and Lee labeled 1000 movie reviews with the 'positive' label and 1000 movie reviews with the 'negative' label.</p>\n",
    "\n",
    "# Dealing with the movie review database\n",
    "\n",
    "Firstly, let's manipulate the movie review database with Python.\n",
    "\n",
    "This ressource is included in the nltk package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg/cv000_29416.txt\n",
      "['neg/cv000_29416.txt', 'neg/cv001_19502.txt', 'neg/cv002_17424.txt', 'neg/cv003_12683.txt', 'neg/cv004_12641.txt', 'neg/cv005_29357.txt', 'neg/cv006_17022.txt', 'neg/cv007_4992.txt', 'neg/cv008_29326.txt', 'neg/cv009_29417.txt']\n",
      "1000 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /home/sharmila/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "nltk.download(\"movie_reviews\")\n",
    "\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "negids = movie_reviews.fileids('neg')\n",
    "posids = movie_reviews.fileids('pos')\n",
    "\n",
    "print(negids[0])\n",
    "print(negids[0:10])\n",
    "print(len(negids),len(posids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in this example, the package movie_reviews defines a funtion fileids which can list the id of the negative ou positive reviews.\n",
    "\n",
    "For me, the corpus is located in C:\\Users\\langlois\\AppData\\Roaming\\nltk_data\\corpora\\movie_reviews\\neg. I invite you to find such a location, and then, you can open positive and negative review documents. For example, find the cv000_29416.txt negative review.\n",
    "\n",
    "The Python API allows to get the text of a review. You have to give to the function 'word' the list of the ids of the reviews you want the raw content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', ',', 'drink', 'and', 'then', 'drive', '.', 'they', 'get', 'into', 'an', 'accident', '.', 'one', 'of', 'the', 'guys', 'dies', ',', 'but', 'his', 'girlfriend', 'continues', 'to', 'see', 'him', 'in', 'her', 'life', ',', 'and', 'has', 'nightmares', '.', 'what', \"'\", 's', 'the', 'deal', '?', 'watch', 'the', 'movie', 'and', '\"', 'sorta', '\"', 'find', 'out', '.', '.', '.', 'critique', ':', 'a', 'mind', '-', 'fuck', 'movie', 'for', 'the', 'teen', 'generation', 'that', 'touches', 'on', 'a', 'very', 'cool', 'idea', ',', 'but', 'presents', 'it', 'in', 'a', 'very', 'bad', 'package', '.', 'which', 'is', 'what', 'makes', 'this', 'review', 'an', 'even', 'harder', 'one', 'to']\n"
     ]
    }
   ],
   "source": [
    "t = movie_reviews.words(fileids = [negids[0]])\n",
    "print(t[0:100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the words are given inside a list, and the tokenization is yet applied. Remark that no lemmatization is applied.\n",
    "\n",
    "OK, now we can access to every movie review, we can access to the document content. Moreover, as the reviews are located in 'pos' and 'neg' directories, we know which ones are 'positive' and which ones are 'negative' (I recall that this labels have been given to reviews by Pang eta al. decisions.\n",
    "\n",
    "Now, we can compute statistics onto this textual material. Let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work for you 1\n",
    "\n",
    "Count the frequency of a word into negative documents and positive documents. For each word $w$ in the corpus (all words in all positive and negative documents), you have to give the number of positive documents $POS(w)$ that contain the word, and the number of negative documents $NEG(w)$ that contain $w$.\n",
    "\n",
    "$$POS(w)= |\\{d \\in C_{p}\\ s.t.\\ w \\in d\\}|$$\n",
    "\n",
    "$$NEG(w)= |\\{d \\in C_{n}\\ s.t.\\ w \\in d\\}|$$\n",
    "\n",
    "where $C_{p}$ is the set of positive documents and $C_{n}$ is the set of negative documents.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Compare the values for positive and negative documents. Do you see something interesting?\n",
    "\n",
    "Try it for \"ugly\", \"bad\", \"good\", \"interesting\", \"movie\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## give your code here\n",
    "pos_count = dict()\n",
    "neg_count = dict()\n",
    "\n",
    "for neg_id in negids:\n",
    "    words = movie_reviews.words(fileids = [neg_id])\n",
    "    words = set(words)\n",
    "    for word in words:\n",
    "        if word in neg_count:\n",
    "            neg_count[word] += 1\n",
    "        else:\n",
    "            neg_count[word] = 1\n",
    "\n",
    "            \n",
    "for pos_id in posids:\n",
    "    words = movie_reviews.words(fileids = [pos_id])\n",
    "    words = set(words)\n",
    "    for word in words:\n",
    "        if word in pos_count:\n",
    "            pos_count[word] += 1\n",
    "        else:\n",
    "            pos_count[word] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many different words are in $C_{p} \\cup C_{n}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of common words: 19129\n"
     ]
    }
   ],
   "source": [
    "## give your code here\n",
    "common = set(pos_count.keys()).intersection(set(neg_count.keys()))\n",
    "print(\"length of common words:\", str(len(common)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the set of words $\\{W_{p/n}\\}$ that are in $C_{p}$ and not in $C_{n}$.\n",
    "\n",
    "In the same way, build the set of words $\\{W_{n/p}\\}$ that are in $C_{n}$ and not in $C_{p}$.\n",
    "\n",
    "Print the most 5 frequent words in $\\{W_{p/n}\\}$ and the most 5 frequent words in $\\{W_{n/p}\\}$.\n",
    "\n",
    "Do you remark if there are clearly 'positive' words in $\\{W_{p/n}\\}$? And if there are clearly 'negative' words in $\\{W_{n/p}\\}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent positive words:\n",
      "[('en', 14), ('lovingly', 14), ('melancholy', 13), ('missteps', 12), ('ideals', 12)]\n",
      "Most frequent negative words:\n",
      "[('degenerates', 13), ('horrid', 10), ('pathetically', 10), ('tedium', 10), ('plodding', 9)]\n"
     ]
    }
   ],
   "source": [
    "## give your code here\n",
    "w_o_p = { key:value for key, value in pos_count.items() if key not in common}\n",
    "w_o_n = { key:value for key, value in neg_count.items() if key not in common}\n",
    "\n",
    "## give your comment below\n",
    "print(\"Most frequent positive words:\")\n",
    "sorted_pos = sorted(w_o_p.items(), key=lambda kv: kv[1], reverse=True)[:5]\n",
    "print(sorted_pos)\n",
    "print(\"Most frequent negative words:\")\n",
    "sorted_neg = sorted(w_o_n.items(), key=lambda kv: kv[1], reverse=True)[:5]\n",
    "print(sorted_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work for you 2\n",
    "\n",
    "I have an hypothsis: I am certain that negative reviews tend to be short and that positive reviews tend to be long. Maybe we could use the information 'length of the review' in order to predict the positivity or the negativity of the review?\n",
    "\n",
    "For that, we could firstly compute the average length of the negative reviews and the positive reviews.\n",
    "\n",
    "Extract statistics for the negative reviews and for the positive reviews. We want the histogram of lengths of documents, by buckets of size equal to 100. Do you see a difference of distribution between negative reviews and positive reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average document length of negative review: 751.256\n",
      "average document length of positive review: 832.564\n"
     ]
    }
   ],
   "source": [
    "## give your code below\n",
    "total = 0\n",
    "count= 0\n",
    "for neg_id in negids:\n",
    "    sents = movie_reviews.words(fileids = [neg_id])  \n",
    "    total += len(sents)\n",
    "    count += 1\n",
    "        \n",
    "print(\"average document length of negative review:\", str(total/count))\n",
    "\n",
    "t = 0   \n",
    "c = 0\n",
    "for pos_id in posids:\n",
    "    sents = movie_reviews.words(fileids = [pos_id])\n",
    "    t += len(sents)\n",
    "    c += 1\n",
    "print(\"average document length of positive review:\", str(t/c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, we want a more precise information.\n",
    "\n",
    "We want the histogram of lengths of documents, by buckets of size equal to 100:\n",
    "\n",
    "+ how many positive documents are of length between 1 and 99?\n",
    "+ how many positive documents are of length between 100 and 199?\n",
    "+ how many positive documents are of length between 200 and 299?\n",
    "+ and so on\n",
    "\n",
    "+ how many negative documents are of length between 1 and 99?\n",
    "+ how many negative documents are of length between 100 and 199?\n",
    "+ how many negative documents are of length between 200 and 299?\n",
    "+ and so on\n",
    "\n",
    "Plot the both histograms on the same graph? Do you see a strong difference of distribution between negative reviews and positive reviews?\n",
    "\n",
    "Then, do you think that the length of the review is a good indicator for the positivity or the negativity of the review?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\t\tDocumentLength\t\tnumber of doc\n",
      "Positive\t\t1-99\t\t\t 0\n",
      "Positive\t\t100-199\t\t\t 4\n",
      "Positive\t\t199-299\t\t\t 23\n",
      "Negative\t\t1-99\t\t\t 987\n",
      "Negative\t\t100-199\t\t\t 13\n",
      "Negative\t\t199-299\t\t\t 0\n"
     ]
    }
   ],
   "source": [
    "## give your code below\n",
    "from matplotlib import pyplot\n",
    "\n",
    "bins = [100,200,300]\n",
    "t_p_1 = 0\n",
    "t_p_2 = 0\n",
    "t_p_3 = 0\n",
    "r_p = 0\n",
    "for pos_id in posids:\n",
    "   \n",
    "    words = movie_reviews.words(fileids = [pos_id])\n",
    "    if len(words) <100:\n",
    "        t_p_1 += 1\n",
    "    elif len(words) >= 100 and len(words) < 200:\n",
    "        t_p_2 += 1\n",
    "    elif len(words) >= 200 and len(words) < 300:\n",
    "        t_p_3 += 1\n",
    "    else:\n",
    "        r_p += 1\n",
    "\n",
    "\n",
    "\n",
    "t_n_1 = 0\n",
    "t_n_2 = 0\n",
    "t_n_3 = 0\n",
    "r_n = 0\n",
    "for neg_id in negids:\n",
    "    sent = movie_reviews.sents(fileids = [neg_id])\n",
    "    if len(sent) <100:\n",
    "        t_n_1 += 1\n",
    "    elif len(sent) >= 100 and len(sent) < 200:\n",
    "        t_n_2 += 1\n",
    "    elif len(sent) >= 200 and len(sent) < 300:\n",
    "        t_n_3 += 1\n",
    "    else:\n",
    "        r_n += 1\n",
    "\n",
    "## give your comments below\n",
    "x = [t_p_1, t_p_2, t_p_3]\n",
    "y = [t_n_1, t_n_2, t_n_3]\n",
    "#pyplot.hist(x, bins)\n",
    "\n",
    "pyplot.hist(x,bins,bins, label='positive')\n",
    "pyplot.legend(loc='upper right')\n",
    "pyplot.show()\n",
    "\n",
    "print(\"category\\t\\tDocumentLength\\t\\tnumber of doc\")\n",
    "print(\"Positive\\t\\t1-99\\t\\t\\t\", t_p_1)\n",
    "print(\"Positive\\t\\t100-199\\t\\t\\t\", t_p_2)\n",
    "print(\"Positive\\t\\t199-299\\t\\t\\t\", t_p_3)\n",
    "print(\"Negative\\t\\t1-99\\t\\t\\t\", t_n_1)\n",
    "print(\"Negative\\t\\t100-199\\t\\t\\t\", t_n_2)\n",
    "print(\"Negative\\t\\t199-299\\t\\t\\t\", t_n_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation of the corpus into a train part and a test part\n",
    "\n",
    "We abandon the idea based on the length.\n",
    "\n",
    "Now we are going to build a predictive model based on the words contained in the review. Our hypothesis is that there are 'positive' words, and 'negative' words. For example, if the review contains 'perfect' it is certainly a positive review.\n",
    "\n",
    "When you want to estimate a predictive model and evaluate it, you have to estimate the predictive model on a train part, and you have to evaluate the predictive performance on a __separate__ test part. Moreover, maybe in the future you will need to estimate hyper-parameters (for example, the weights of the linear combination between two models): then you havealse to deal with a __separate__ development part (also called tuning set).\n",
    "\n",
    "For, that, I propose the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "200\n",
      "200\n",
      "600\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "train_negids = negids[0:int(0.6*len(negids))]\n",
    "dev_negids = negids[int(0.6*len(negids)):int(0.8*len(negids))]\n",
    "test_negids = negids[int(0.8*len(negids)):]\n",
    "\n",
    "train_posids = posids[0:int(0.6*len(posids))]\n",
    "dev_posids = posids[int(0.6*len(posids)):int(0.8*len(posids))]\n",
    "test_posids = posids[int(0.8*len(posids)):]\n",
    "\n",
    "print(len(train_negids))\n",
    "print(len(dev_negids))\n",
    "print(len(test_negids))\n",
    "print(len(train_posids))\n",
    "print(len(dev_posids))\n",
    "print(len(test_posids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The predictive model\n",
    "\n",
    "[Dave et al., 2003] propose the following strategy to predict the label of a movie review :\n",
    "\n",
    "$$\\mathcal{P}$$\n",
    "\n",
    "The score of a word $w$ is defined by:\n",
    "\n",
    "$$ score(w) = \\frac{P(w|\\mathcal{P})-P(w|\\mathcal{N})}{P(w|\\mathcal{P})+P(w|\\mathcal{N})}$$\n",
    "\n",
    "Where $P(w|\\mathcal{P})$ is the probability that the word $w$ occurs in a positive document, and $P(w|\\mathcal{N})$ is the probability that the word $w$ occurs in a negative document of the training corpus.\n",
    "\n",
    "Then, the 'positivity' of a document $d$ is given by:\n",
    "\n",
    "$$eval(d) = \\sum_{w\\ \\in \\ set(d)} score(w)$$\n",
    "\n",
    "where the sum is applyed on the set of words in $d$ (a word occuring several times in $d$ is counted only once in the sum).\n",
    "\n",
    "Then, the decision follows the following condition: if  $eval(d) > 0$ then a document in the test part positive else the document is negative\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating the parameters of the predictive model\n",
    "\n",
    "The parameters of this predictive model are all the $P(w|\\mathcal{P})$ and the $P(w|\\mathcal{N})$ for all the words $w$ in the positive and negative documents.\n",
    "\n",
    "__Work__: compute these values on the training corpus.\n",
    "\n",
    "For estimating the $P(w|\\mathcal{P})$, iterate on all the positive documents in the train positive part. $P(w|\\mathcal{P})$ is estimated by the formula:\n",
    "\n",
    "$$P(w|\\mathcal{P}) = \\frac{|sum_{d \\in \\{\\mathcal{P}_{train}\\}} \\delta(w,d)|}{|\\{\\mathcal{P}_{train}\\}|}$$\n",
    "\n",
    "where $\\{\\mathcal{P}_{train}\\}$ is the set of documents in the positive train part, and  $\\delta(w,d)$ is equal to 1 if $w$ is in $d$, 0 otherwise. \n",
    "\n",
    "The formula is the same for $P(w|\\mathcal{N})$:\n",
    "\n",
    "$$P(w|\\mathcal{N}) = \\frac{|sum_{d \\in \\{\\mathcal{N}_{train}\\}} \\delta(w,d)|}{|\\{\\mathcal{N}_{train}\\}|}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## give your code below\n",
    "def test(document):\n",
    "    eval_s = 0\n",
    "    for word in set(document):\n",
    "        p_w_p = pos_count.get(word,0)/len(posids)\n",
    "        p_w_n = neg_count.get(word,0)/len(negids)\n",
    "        score_w = (p_w_p - p_w_n)/(p_w_p + p_w_n)\n",
    "        eval_s += score_w\n",
    "    return eval_s\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the predictive model\n",
    "\n",
    "We want to know if, on the test corpus, the decision strategy described above performs well or not. We want to know if when a document is labeled positive by Pang et al., the document is predicted as positive by the model, and so on for a negative document.\n",
    "\n",
    "We are going to evaluate the following statistics on the test corpus.\n",
    "\n",
    "When the model predict 'positive', the document could be actually 'positive': this is a true positive ($tp$). But, the document may be actually 'negative': this is a false positive ($fp$).\n",
    "\n",
    "In the same way, when the model predict 'negative', the document could be actually 'negative': this is a true negative ($tn$). But, the document may be actually 'positive': this is a false negative ($fn$).\n",
    "\n",
    "Note that, there are the following constraints:\n",
    "\n",
    "+ $tp+fp=n$\n",
    "+ $fn+tn=n$\n",
    "+ $tp+fn=n$\n",
    "+ $fp+tn=n$ \n",
    "\n",
    "where $n$ is the number of documents (positive or negative).\n",
    "\n",
    "these notations can be sumarized into the following table\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>  </td>\n",
    "        <td>  </td>\n",
    "        <td colspan=2 style=\"text-align: center\"> True label </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>  </td>\n",
    "        <td>  </td>\n",
    "        <td> positive </td>\n",
    "        <td> negative </td>\n",
    "    </tr>    \n",
    "    <tr>\n",
    "        <td rowspan=2 style=\"vertical-align: center\"> Predicted label </td>\n",
    "        <td> positive </td>\n",
    "        <td> true positive </td>\n",
    "        <td> false positive </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> negative </td>\n",
    "        <td> false negative </td>\n",
    "        <td> true negative </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Be careful: unfortunately, there is a trap in the used vocabulary; you have the labels 'positive' and 'negative' and these labels can be 'true positive', 'true negative', 'false positive', or 'false negative'. This is confusing. Sorry for that.\n",
    "\n",
    "The recall evaluates how much the model can retrieve the correct decision:\n",
    "\n",
    "$$recall = \\frac{tp}{tp+fn}$$\n",
    "\n",
    "The precision evaluates if the model does not sur-generate the positive or negative prediction:\n",
    "\n",
    "$$precision = \\frac{tp}{tp+fp}$$\n",
    "\n",
    "Moreover, we can use the F1 measure which deals with precision and recall:\n",
    "\n",
    "$$F1 = 2 \\times \\frac{precision \\times recall}{precision + recall}$$\n",
    "\n",
    "__Work__: evaluate on the test corpus the recall, the precision and the F1 measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.970873786407767, 0.9852216748768473)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def evaluation(pos_ids, neg_ids,alpha=0):\n",
    "    \n",
    "    t_p = 0\n",
    "    t_n = 0\n",
    "    f_p = 0\n",
    "    f_n = 0\n",
    "    for each in pos_ids:\n",
    "        score = test(movie_reviews.words(each))\n",
    "\n",
    "        if score >alpha:\n",
    "            t_p += 1\n",
    "        else:\n",
    "            f_n += 1\n",
    "    for each in neg_ids:\n",
    "        score = test(movie_reviews.words(each))\n",
    "        if score >alpha:\n",
    "            f_p += 1\n",
    "        else:\n",
    "            t_n += 1\n",
    "\n",
    "    #print(\"Accuracy is:\", str((t_p+t_n)/(t_p+ t_n+ f_p+ f_n)))\n",
    "    precision = t_p/(t_p+f_p)\n",
    "    recall = t_p/(t_p+f_n)\n",
    "  \n",
    "    f1 = (2*precision*recall)/(precision+recall)\n",
    "    #print(\"Precision is:\", str(precision))\n",
    "    #print(\"Recall is:\", str(recall))\n",
    "    #print(\"F1 Score is:\", str((2*precision*recall)/(precision+recall)))\n",
    "    return recall, precision,f1\n",
    "evaluation(test_posids, test_negids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning the model\n",
    "\n",
    "In the model by \\[Dave et al., 2003\\] a document $d$ is considered as positive if $eval(d)>0$. But maybe this value is not very precise. For exemple, if a document has a value $eval$ equal to 0.02, it has chance to be negative.\n",
    "\n",
    "To check that, replace the decision $eval(d)>0 \\Rightarrow positive$ by  $eval(d)>\\alpha \\Rightarrow positive$ where $\\alpha$ is a threshold varying from a negative value to a positive value. Explore the range values of the $eval$ score on the test corpus. Iterate $\\alpha$ from the minimum value of $\\alpha$ to the maximum value of $\\alpha$. You can not scan all the values: choose a step, and refine. For each tested value, compute the recall and the precision on the __development__ part, and graph the curve (precision,recall).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## give the code here\n",
    "alphas = np.linspace(-5,5,100)\n",
    "recalls = []\n",
    "precisions = []\n",
    "f1_max = 0\n",
    "max_alpha = 0\n",
    "for alpha in alphas:\n",
    "    recall, precision, f1 = evaluation(pos_ids=dev_posids, neg_ids=dev_negids, alpha=alpha)\n",
    "    recalls.append(recall)\n",
    "    precisions.append(precision)\n",
    "    if f1_max<f1:\n",
    "        f1_max = f1\n",
    "        max_alpha = alpha\n",
    "\n",
    "pyplot.plot(alphas,recalls,linestyle='--',label = \"Recall\")\n",
    "pyplot.plot(alphas,precisions, label=\"Precision\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0808080808080813 0.9925187032418954\n"
     ]
    }
   ],
   "source": [
    "print(max_alpha, f1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then check for which value of $\\alpha$ the F1 measure is the highest. Apply this value on the test part. Is the F1 measure increased?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.9900990099009901, 0.9950248756218906)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## give the code below\n",
    "evaluation(test_posids, test_negids, alpha=max_alpha)\n",
    "\n",
    "## give your comment below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
